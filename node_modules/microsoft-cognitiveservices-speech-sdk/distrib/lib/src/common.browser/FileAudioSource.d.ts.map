{"version":3,"sources":["src/common.browser/FileAudioSource.ts"],"names":[],"mappings":";AAGA,OAAO,EAEH,wBAAwB,EAE3B,MAAM,0BAA0B,CAAC;AAClC,OAAO,EAEH,gBAAgB,EAYhB,WAAW,EACX,YAAY,EACZ,gBAAgB,EAInB,MAAM,mBAAmB,CAAC;AAC3B,OAAO,EAAqB,qBAAqB,EAAE,MAAM,gCAAgC,CAAC;AAE1F,qBAAa,eAAgB,YAAW,YAAY;IAEhD,OAAO,CAAC,sBAAsB,CAAiC;IAE/D,OAAO,CAAC,WAAW,CAA8C;IAEjE,OAAO,CAAC,MAAM,CAAS;IAEvB,OAAO,CAAC,UAAU,CAAgC;IAElD,OAAO,CAAC,QAAQ,CAAO;IAEvB,OAAO,CAAC,aAAa,CAAc;gBAEhB,IAAI,EAAE,IAAI,EAAE,aAAa,CAAC,EAAE,MAAM;IASrD,IAAW,MAAM,IAAI,OAAO,CAAC,qBAAqB,CAAC,CAElD;IAED,IAAW,IAAI,IAAI,OAAO,CAAC,IAAI,GAAG,MAAM,CAAC,CAExC;IAEM,MAAM,sBAcZ;IAEM,EAAE,eAER;IAEM,MAAM,qDAoBZ;IAEM,MAAM,gCAMZ;IAEM,OAAO,sBAYb;IAED,IAAW,MAAM,IAAI,WAAW,CAAC,gBAAgB,CAAC,CAEjD;IAED,IAAW,UAAU,IAAI,OAAO,CAAC,wBAAwB,CAAC,CAYzD;IAED,OAAO,CAAC,UAAU;YAkDJ,MAAM;IAoCpB,OAAO,CAAC,OAAO,CAGd;CACJ","file":"FileAudioSource.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport {\r\n    connectivity,\r\n    ISpeechConfigAudioDevice,\r\n    type,\r\n} from \"../common.speech/Exports\";\r\nimport {\r\n    AudioSourceErrorEvent,\r\n    AudioSourceEvent,\r\n    AudioSourceInitializingEvent,\r\n    AudioSourceOffEvent,\r\n    AudioSourceReadyEvent,\r\n    AudioStreamNodeAttachedEvent,\r\n    AudioStreamNodeAttachingEvent,\r\n    AudioStreamNodeDetachedEvent,\r\n    AudioStreamNodeErrorEvent,\r\n    ChunkedArrayBufferStream,\r\n    createNoDashGuid,\r\n    Deferred,\r\n    Events,\r\n    EventSource,\r\n    IAudioSource,\r\n    IAudioStreamNode,\r\n    IStreamChunk,\r\n    IStringDictionary,\r\n    Stream,\r\n} from \"../common/Exports\";\r\nimport { AudioStreamFormat, AudioStreamFormatImpl } from \"../sdk/Audio/AudioStreamFormat\";\r\n\r\nexport class FileAudioSource implements IAudioSource {\r\n\r\n    private privAudioFormatPromise: Promise<AudioStreamFormatImpl>;\r\n\r\n    private privStreams: IStringDictionary<Stream<ArrayBuffer>> = {};\r\n\r\n    private privId: string;\r\n\r\n    private privEvents: EventSource<AudioSourceEvent>;\r\n\r\n    private privFile: File;\r\n\r\n    private privHeaderEnd: number = 44;\r\n\r\n    public constructor(file: File, audioSourceId?: string) {\r\n        this.privId = audioSourceId ? audioSourceId : createNoDashGuid();\r\n        this.privEvents = new EventSource<AudioSourceEvent>();\r\n        this.privFile = file;\r\n\r\n        // Read the header.\r\n        this.privAudioFormatPromise = this.readHeader();\r\n    }\r\n\r\n    public get format(): Promise<AudioStreamFormatImpl> {\r\n        return this.privAudioFormatPromise;\r\n    }\r\n\r\n    public get blob(): Promise<Blob | Buffer> {\r\n        return Promise.resolve(this.privFile);\r\n    }\r\n\r\n    public turnOn = (): Promise<void> => {\r\n        if (typeof FileReader === \"undefined\") {\r\n            const errorMsg = \"Browser does not support FileReader.\";\r\n            this.onEvent(new AudioSourceErrorEvent(errorMsg, \"\")); // initialization error - no streamid at this point\r\n            return Promise.reject(errorMsg);\r\n        } else if (this.privFile.name.lastIndexOf(\".wav\") !== this.privFile.name.length - 4) {\r\n            const errorMsg = this.privFile.name + \" is not supported. Only WAVE files are allowed at the moment.\";\r\n            this.onEvent(new AudioSourceErrorEvent(errorMsg, \"\"));\r\n            return Promise.reject(errorMsg);\r\n        }\r\n\r\n        this.onEvent(new AudioSourceInitializingEvent(this.privId)); // no stream id\r\n        this.onEvent(new AudioSourceReadyEvent(this.privId));\r\n        return;\r\n    }\r\n\r\n    public id = (): string => {\r\n        return this.privId;\r\n    }\r\n\r\n    public attach = async (audioNodeId: string): Promise<IAudioStreamNode> => {\r\n        this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\r\n\r\n        const stream: Stream<ArrayBuffer> = await this.upload(audioNodeId);\r\n\r\n        this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\r\n        return Promise.resolve({\r\n            detach: async (): Promise<void> => {\r\n                stream.readEnded();\r\n                delete this.privStreams[audioNodeId];\r\n                this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\r\n                await this.turnOff();\r\n            },\r\n            id: () => {\r\n                return audioNodeId;\r\n            },\r\n            read: (): Promise<IStreamChunk<ArrayBuffer>> => {\r\n                return stream.read();\r\n            },\r\n        });\r\n    }\r\n\r\n    public detach = (audioNodeId: string): void => {\r\n        if (audioNodeId && this.privStreams[audioNodeId]) {\r\n            this.privStreams[audioNodeId].close();\r\n            delete this.privStreams[audioNodeId];\r\n            this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\r\n        }\r\n    }\r\n\r\n    public turnOff = (): Promise<void> => {\r\n        for (const streamId in this.privStreams) {\r\n            if (streamId) {\r\n                const stream = this.privStreams[streamId];\r\n                if (stream && !stream.isClosed) {\r\n                    stream.close();\r\n                }\r\n            }\r\n        }\r\n\r\n        this.onEvent(new AudioSourceOffEvent(this.privId)); // no stream now\r\n        return Promise.resolve();\r\n    }\r\n\r\n    public get events(): EventSource<AudioSourceEvent> {\r\n        return this.privEvents;\r\n    }\r\n\r\n    public get deviceInfo(): Promise<ISpeechConfigAudioDevice> {\r\n        return this.privAudioFormatPromise.then<ISpeechConfigAudioDevice>((result: AudioStreamFormatImpl) => {\r\n            return Promise.resolve({\r\n                bitspersample: result.bitsPerSample,\r\n                channelcount: result.channels,\r\n                connectivity: connectivity.Unknown,\r\n                manufacturer: \"Speech SDK\",\r\n                model: \"File\",\r\n                samplerate: result.samplesPerSec,\r\n                type: type.File,\r\n            });\r\n        });\r\n    }\r\n\r\n    private readHeader(): Promise<AudioStreamFormatImpl> {\r\n        // Read the wave header.\r\n        const maxHeaderSize: number = 128;\r\n        const header: Blob = this.privFile.slice(0, maxHeaderSize);\r\n        const headerReader: FileReader = new FileReader();\r\n\r\n        const headerResult: Deferred<AudioStreamFormatImpl> = new Deferred<AudioStreamFormatImpl>();\r\n\r\n        const processHeader = (event: Event): void => {\r\n            const header: ArrayBuffer = (event.target as FileReader).result as ArrayBuffer;\r\n\r\n            const view: DataView = new DataView(header);\r\n\r\n            const getWord = (index: number): string => {\r\n                return String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));\r\n            };\r\n\r\n            // RIFF 4 bytes.\r\n            if (\"RIFF\" !== getWord(0)) {\r\n                headerResult.reject(\"Invalid WAV header in file, RIFF was not found\");\r\n            }\r\n\r\n            // length, 4 bytes\r\n            // RIFF Type & fmt 8 bytes\r\n            if (\"WAVE\" !== getWord(8) || \"fmt \" !== getWord(12)) {\r\n                headerResult.reject(\"Invalid WAV header in file, WAVEfmt was not found\");\r\n            }\r\n\r\n            const formatSize: number = view.getInt32(16, true);\r\n            const channelCount: number = view.getUint16(22, true);\r\n            const sampleRate: number = view.getUint32(24, true);\r\n            const bitsPerSample: number = view.getUint16(34, true);\r\n            // Confirm if header is 44 bytes long.\r\n            let pos: number = 36 + Math.max(formatSize - 16, 0);\r\n            for (; getWord(pos) !== \"data\"; pos += 2) {\r\n              if (pos > maxHeaderSize - 8) {\r\n                  headerResult.reject(\"Invalid WAV header in file, data block was not found\");\r\n              }\r\n            }\r\n\r\n            this.privHeaderEnd = pos + 8;\r\n\r\n            headerResult.resolve(AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount) as AudioStreamFormatImpl);\r\n        };\r\n\r\n        headerReader.onload = processHeader;\r\n        headerReader.readAsArrayBuffer(header);\r\n        return headerResult.promise;\r\n    }\r\n\r\n    private async upload(audioNodeId: string): Promise<Stream<ArrayBuffer>> {\r\n        await this.turnOn();\r\n\r\n        const format: AudioStreamFormatImpl = await this.privAudioFormatPromise;\r\n        const reader: FileReader = new FileReader();\r\n        const stream = new ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);\r\n\r\n        this.privStreams[audioNodeId] = stream;\r\n\r\n        const processFile = (event: Event): void => {\r\n            if (stream.isClosed) {\r\n                return; // output stream was closed (somebody called TurnOff). We're done here.\r\n            }\r\n\r\n            stream.writeStreamChunk({\r\n                buffer: reader.result as ArrayBuffer,\r\n                isEnd: false,\r\n                timeReceived: Date.now(),\r\n            });\r\n            stream.close();\r\n        };\r\n\r\n        reader.onload = processFile;\r\n\r\n        reader.onerror = (event: ProgressEvent) => {\r\n            const errorMsg = `Error occurred while processing '${this.privFile.name}'. ${event}`;\r\n            this.onEvent(new AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));\r\n            throw new Error(errorMsg);\r\n        };\r\n\r\n        const chunk = this.privFile.slice(this.privHeaderEnd);\r\n        reader.readAsArrayBuffer(chunk);\r\n\r\n        return stream;\r\n    }\r\n\r\n    private onEvent = (event: AudioSourceEvent): void => {\r\n        this.privEvents.onEvent(event);\r\n        Events.instance.onEvent(event);\r\n    }\r\n}\r\n"]}